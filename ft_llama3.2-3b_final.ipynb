{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":120005,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":100936,"modelId":121027}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n%pip install -U torch \n%pip install -U transformers \n%pip install -U datasets \n%pip install -U accelerate \n%pip install -U peft \n%pip install -U trl \n%pip install -U bitsandbytes \n%pip install -U wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:53:53.699021Z","iopub.execute_input":"2025-01-13T12:53:53.699306Z","iopub.status.idle":"2025-01-13T12:57:22.836779Z","shell.execute_reply.started":"2025-01-13T12:53:53.699283Z","shell.execute_reply":"2025-01-13T12:57:22.835651Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\nimport os, torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:57:34.608601Z","iopub.execute_input":"2025-01-13T12:57:34.608927Z","iopub.status.idle":"2025-01-13T12:57:49.233932Z","shell.execute_reply.started":"2025-01-13T12:57:34.608902Z","shell.execute_reply":"2025-01-13T12:57:49.233083Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"hf\")\nlogin(token = hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:58:16.352484Z","iopub.execute_input":"2025-01-13T12:58:16.353224Z","iopub.status.idle":"2025-01-13T12:58:16.648580Z","shell.execute_reply.started":"2025-01-13T12:58:16.353193Z","shell.execute_reply":"2025-01-13T12:58:16.647886Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"wb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='train2', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:58:19.014209Z","iopub.execute_input":"2025-01-13T12:58:19.014547Z","iopub.status.idle":"2025-01-13T12:58:31.903473Z","shell.execute_reply.started":"2025-01-13T12:58:19.014519Z","shell.execute_reply":"2025-01-13T12:58:31.902845Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mishitas2365\u001b[0m (\u001b[33mishitas2365-indian-institute-of-technology-indore\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250113_125825-ffjc7zl9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2/runs/ffjc7zl9' target=\"_blank\">radiant-thunder-2</a></strong> to <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2' target=\"_blank\">https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2/runs/ffjc7zl9' target=\"_blank\">https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2/runs/ffjc7zl9</a>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3.2/transformers/3b-instruct/1\"\nnew_model = \"llama-3-3b-it-personaB\"\ntorch_dtype = torch.float16\nattn_implementation = \"eager\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:59:08.683252Z","iopub.execute_input":"2025-01-13T12:59:08.683563Z","iopub.status.idle":"2025-01-13T12:59:08.688251Z","shell.execute_reply.started":"2025-01-13T12:59:08.683538Z","shell.execute_reply":"2025-01-13T12:59:08.687384Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    torch_dtype=torch.float32,   \n    attn_implementation=\"sdpa\"    \n)\n\n#eager and torch_dtype tha hi nahi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:59:11.448940Z","iopub.execute_input":"2025-01-13T12:59:11.449265Z","iopub.status.idle":"2025-01-13T13:00:00.636366Z","shell.execute_reply.started":"2025-01-13T12:59:11.449239Z","shell.execute_reply":"2025-01-13T13:00:00.635639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1f6504b25bb4639a9ec29b6b35c9afb"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:00:21.220215Z","iopub.execute_input":"2025-01-13T13:00:21.220513Z","iopub.status.idle":"2025-01-13T13:00:21.942641Z","shell.execute_reply.started":"2025-01-13T13:00:21.220491Z","shell.execute_reply":"2025-01-13T13:00:21.941718Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"tokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:00:24.418336Z","iopub.execute_input":"2025-01-13T13:00:24.418624Z","iopub.status.idle":"2025-01-13T13:00:24.423159Z","shell.execute_reply.started":"2025-01-13T13:00:24.418603Z","shell.execute_reply":"2025-01-13T13:00:24.422306Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"tokenizer.chat_template = None\nmodel, tokenizer = setup_chat_format(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:00:28.825990Z","iopub.execute_input":"2025-01-13T13:00:28.826323Z","iopub.status.idle":"2025-01-13T13:00:35.277562Z","shell.execute_reply.started":"2025-01-13T13:00:28.826296Z","shell.execute_reply":"2025-01-13T13:00:35.276896Z"}},"outputs":[{"name":"stderr","text":"The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\nmodules = find_all_linear_names(model)\nprint(modules)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:00:40.942196Z","iopub.execute_input":"2025-01-13T13:00:40.942547Z","iopub.status.idle":"2025-01-13T13:00:40.950550Z","shell.execute_reply.started":"2025-01-13T13:00:40.942516Z","shell.execute_reply":"2025-01-13T13:00:40.949859Z"}},"outputs":[{"name":"stdout","text":"['k_proj', 'gate_proj', 'down_proj', 'v_proj', 'q_proj', 'up_proj', 'o_proj']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:00:45.261126Z","iopub.execute_input":"2025-01-13T13:00:45.261447Z","iopub.status.idle":"2025-01-13T13:00:45.741255Z","shell.execute_reply.started":"2025-01-13T13:00:45.261421Z","shell.execute_reply":"2025-01-13T13:00:45.740586Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load the dataset and shuffle it\nds = load_dataset(\"Cynaptics/persona-chat\")\nds = ds.shuffle(seed=65)  # Shuffle the dataset to randomize the rows\n\n# Select 6,000 random rows from the train split\nds = ds['train'].select(range(6000))  # Select the first 6,000 rows after shuffling\n\n# Verify the sampled dataset\nprint(ds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:00:49.991278Z","iopub.execute_input":"2025-01-13T13:00:49.991576Z","iopub.status.idle":"2025-01-13T13:00:52.380952Z","shell.execute_reply.started":"2025-01-13T13:00:49.991551Z","shell.execute_reply":"2025-01-13T13:00:52.380179Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb447b409ada46b78420084dccaf3dc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/11.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c43d52abcd419c8d928e9e89408ec3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9434511e3e674f0c88f8667949ed77ff"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['conv_id', 'persona_b', 'dialogue', 'reference', '__index_level_0__'],\n    num_rows: 6000\n})\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def format_chat_template(row):\n    persona_statements = \" \".join(row[\"persona_b\"])  # Join the statements into a single string\n    # Use only the current row's Persona B as the system message\n    persona = {\"role\": \"system\", \"content\": f\"Persona B's characteristics: {row['persona_b']}\"}\n    \n    # Process the conversation column\n    conversation = row[\"dialogue\"]\n    chat_history = []\n    for i, turn in enumerate(row[\"dialogue\"]):\n        turn_cleaned = turn.replace(\"Persona A: \", \"\").replace(\"Persona B: \", \"\")\n        role = \"user\" if i % 2 == 0 else \"assistant\"  # Alternating roles\n        chat_history.append({\"role\": role, \"content\": turn_cleaned})\n    \n    # Final assistant response from the answer column\n    final_response = {\"role\": \"assistant\", \"content\": row[\"reference\"]}\n    \n    # Combine everything\n    row_json = [persona] + chat_history + [final_response]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:00:58.540655Z","iopub.execute_input":"2025-01-13T13:00:58.541047Z","iopub.status.idle":"2025-01-13T13:00:58.547600Z","shell.execute_reply.started":"2025-01-13T13:00:58.541017Z","shell.execute_reply":"2025-01-13T13:00:58.546860Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Apply the formatting to the entire dataset\nprocessed_dataset = ds.map(format_chat_template, num_proc=4)\n\n# Check a sample row\nprint(processed_dataset[0][\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:01:01.959460Z","iopub.execute_input":"2025-01-13T13:01:01.959746Z","iopub.status.idle":"2025-01-13T13:01:03.394664Z","shell.execute_reply.started":"2025-01-13T13:01:01.959724Z","shell.execute_reply":"2025-01-13T13:01:03.393672Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/6000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71c8c746eb4044cba1c7498f61518bec"}},"metadata":{}},{"name":"stdout","text":"<|im_start|>system\nPersona B's characteristics: [\"I've been working at my current job for a year.\", 'My vintage cars are my pride and joy.', 'i am a very short woman.', 'I want to inspire people with my webcomic and music.', 'i m a girl.']<|im_end|>\n<|im_start|>user\nWhat is your name?<|im_end|>\n<|im_start|>assistant\nHi, I'm Dillon How are you today?<|im_end|>\n<|im_start|>user\nI'm doing well, thanks for asking!<|im_end|>\n<|im_start|>assistant\nI like to draw and write, but also as a big fan of vintage cars.<|im_end|>\n<|im_start|>user\nOh that's cool, I have always wanted to learn what it is you can draw?<|im_end|>\n<|im_start|>assistant\nJust keep practicing and you will get better. You could also take some lessons or research tutorials online to practise with!<|im_end|>\n<|im_start|>user\nThanks for the advice, I will definitely look into it.<|im_end|>\n<|im_start|>assistant\nWhat else would you like to do?<|im_end|>\n<|im_start|>user\nI like to listen and watch movies, also has love for a horse.<|im_end|>\n<|im_start|>assistant\nOoh, that's great! I love animals. What kind of music do you like?<|im_end|>\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# Assuming `ds` is your DatasetDict object\n# Apply train_test_split to the \"train\" portion of the DatasetDict\ntrain_test_split = processed_dataset.train_test_split(test_size=0.1, seed=42)\n\n# Update the DatasetDict to include the new train and validation splits\nprocessed_dataset = DatasetDict({\n    \"train\": train_test_split[\"train\"],\n    \"test\": train_test_split[\"test\"]\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:01:10.554686Z","iopub.execute_input":"2025-01-13T13:01:10.555042Z","iopub.status.idle":"2025-01-13T13:01:10.570580Z","shell.execute_reply.started":"2025-01-13T13:01:10.555017Z","shell.execute_reply":"2025-01-13T13:01:10.569761Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"new_model_base_dir = \"llama-3-3b-it-personaB\"  # Base directory for the model\ncheckpoint_prefix = \"step_checkpoint\"  # Add a prefix for each checkpoint\noutput_dir = os.path.join(new_model_base_dir, checkpoint_prefix)  # Final output directory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:01:26.572121Z","iopub.execute_input":"2025-01-13T13:01:26.572411Z","iopub.status.idle":"2025-01-13T13:01:26.577270Z","shell.execute_reply.started":"2025-01-13T13:01:26.572388Z","shell.execute_reply":"2025-01-13T13:01:26.576364Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",   #16bit\n    num_train_epochs=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=50,\n    logging_steps=1,\n    save_steps=200,  # 100\n    save_total_limit=3,  # Keep only the 3 most recent checkpoints\n    save_strategy=\"steps\",  \n    warmup_steps=50,\n    logging_strategy=\"steps\",\n    learning_rate=1e-4,  # 3e-5\n    fp16=False,\n    bf16=True, #true  \n    group_by_length=True,\n    report_to=\"wandb\"\n)\n# Log the output directory for clarity\nprint(f\"Model checkpoints will be saved in: {training_arguments.output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:01:36.700116Z","iopub.execute_input":"2025-01-13T13:01:36.700408Z","iopub.status.idle":"2025-01-13T13:01:36.732240Z","shell.execute_reply.started":"2025-01-13T13:01:36.700385Z","shell.execute_reply":"2025-01-13T13:01:36.731353Z"}},"outputs":[{"name":"stdout","text":"Model checkpoints will be saved in: llama-3-3b-it-personaB/step_checkpoint\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=processed_dataset[\"train\"],\n    eval_dataset=processed_dataset[\"test\"],\n    peft_config=peft_config,\n    processing_class=tokenizer,  # Use the tokenizer object\n    args=training_arguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:01:50.339051Z","iopub.execute_input":"2025-01-13T13:01:50.339352Z","iopub.status.idle":"2025-01-13T13:01:55.342567Z","shell.execute_reply.started":"2025-01-13T13:01:50.339329Z","shell.execute_reply":"2025-01-13T13:01:55.341888Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3988b4aa184958a9d183e1f6bf81f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28ceb838c8c74ba2a3082c4e2cb400d6"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"model.config.use_cache = False\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T13:02:07.603335Z","iopub.execute_input":"2025-01-13T13:02:07.603654Z","iopub.status.idle":"2025-01-13T21:50:40.872378Z","shell.execute_reply.started":"2025-01-13T13:02:07.603629Z","shell.execute_reply":"2025-01-13T21:50:40.871461Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2700' max='2700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2700/2700 8:48:25, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>5.186800</td>\n      <td>2.241447</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>4.162700</td>\n      <td>2.049918</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>3.979700</td>\n      <td>2.022768</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.738800</td>\n      <td>1.987654</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>4.284100</td>\n      <td>1.963702</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>4.098600</td>\n      <td>1.944645</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>4.158900</td>\n      <td>1.932925</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.407300</td>\n      <td>1.918638</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>4.014400</td>\n      <td>1.905796</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>4.203100</td>\n      <td>1.897264</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>3.849400</td>\n      <td>1.881906</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.685600</td>\n      <td>1.867969</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>3.793900</td>\n      <td>1.859380</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.735800</td>\n      <td>1.847992</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>3.727100</td>\n      <td>1.840888</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.930100</td>\n      <td>1.831333</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>3.475000</td>\n      <td>1.826100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.631500</td>\n      <td>1.816628</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>3.628400</td>\n      <td>1.810472</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.754600</td>\n      <td>1.800969</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>4.031300</td>\n      <td>1.793143</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>3.319900</td>\n      <td>1.784475</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>3.405000</td>\n      <td>1.781890</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.363400</td>\n      <td>1.774220</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>3.558100</td>\n      <td>1.768715</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>4.136700</td>\n      <td>1.761133</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>3.790000</td>\n      <td>1.755590</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>3.054200</td>\n      <td>1.748746</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>3.299200</td>\n      <td>1.744481</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.421300</td>\n      <td>1.739449</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>3.644700</td>\n      <td>1.734125</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>3.229900</td>\n      <td>1.726865</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>3.000800</td>\n      <td>1.720569</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>3.237200</td>\n      <td>1.716710</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>3.507400</td>\n      <td>1.713752</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>3.317100</td>\n      <td>1.708841</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>3.646300</td>\n      <td>1.703932</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>3.763200</td>\n      <td>1.700514</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>4.138200</td>\n      <td>1.696053</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>3.172900</td>\n      <td>1.693117</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>3.444700</td>\n      <td>1.688365</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>3.241000</td>\n      <td>1.685434</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>3.316800</td>\n      <td>1.682698</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>3.418900</td>\n      <td>1.678619</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>3.601100</td>\n      <td>1.675607</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>3.920500</td>\n      <td>1.673501</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>2.944000</td>\n      <td>1.671318</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>2.932300</td>\n      <td>1.670144</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>3.186300</td>\n      <td>1.667431</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.577100</td>\n      <td>1.665353</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>3.572000</td>\n      <td>1.663668</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>3.557400</td>\n      <td>1.662722</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>3.240800</td>\n      <td>1.662308</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>3.751200</td>\n      <td>1.662055</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\nTrainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2700, training_loss=3.5836684241118255, metrics={'train_runtime': 31711.2662, 'train_samples_per_second': 0.17, 'train_steps_per_second': 0.085, 'total_flos': 2.840165305812787e+16, 'train_loss': 3.5836684241118255, 'epoch': 1.0})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T21:52:59.209341Z","iopub.execute_input":"2025-01-13T21:52:59.209655Z","iopub.status.idle":"2025-01-13T21:53:00.951939Z","shell.execute_reply.started":"2025-01-13T21:52:59.209630Z","shell.execute_reply":"2025-01-13T21:53:00.951259Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▇▆▅█▇▇▇▇▆▆▇█▇▇█▇▇▇▇▇▃▂▂▂▁▂▁▂▁▂▁▅▅▅▆▆▆▆▅▆</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄▄▄▄██▄▄▄▄▄▄▄▄▄</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▄█▄▄▄▄▄▄█▄▄▄▄▄▄▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▃▂▂▂▂▂▂▃▁▂▂▂▅▂▂▂▄▃▂▂▃▅▃▆▃▅█▆▃▆▄▄▄▅▆▅▃▇▄▄</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▇▇▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>▇▅▅▆█▂▅▄▃▅▅▅▄▄▄▅▁▆▅▆▂▄▄▂▆▄▄▂▃▄▃▆▄▄▃▆▅▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.66205</td></tr><tr><td>eval/runtime</td><td>435.2444</td></tr><tr><td>eval/samples_per_second</td><td>1.379</td></tr><tr><td>eval/steps_per_second</td><td>1.379</td></tr><tr><td>total_flos</td><td>2.840165305812787e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>2700</td></tr><tr><td>train/grad_norm</td><td>6.45393</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>3.7512</td></tr><tr><td>train_loss</td><td>3.58367</td></tr><tr><td>train_runtime</td><td>31711.2662</td></tr><tr><td>train_samples_per_second</td><td>0.17</td></tr><tr><td>train_steps_per_second</td><td>0.085</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">radiant-thunder-2</strong> at: <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2/runs/ffjc7zl9' target=\"_blank\">https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2/runs/ffjc7zl9</a><br> View project at: <a href='https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2' target=\"_blank\">https://wandb.ai/ishitas2365-indian-institute-of-technology-indore/train2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250113_125825-ffjc7zl9/logs</code>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"import os\nimport zipfile\nfrom tqdm import tqdm\n\n# Define the directory to zip and output zip file\ndir_to_zip = \"/kaggle/working/llama-3-3b-it-personaB/step_checkpoint/checkpoint-2700\"\noutput_zip_file = \"checkpoint-2700_3b_ft.zip\"\n\n# Get all files to zip\nfile_paths = []\nfor root, _, files in os.walk(dir_to_zip):\n    for file in files:\n        file_paths.append(os.path.join(root, file))\n\n# Zip the files with tqdm progress bar\nwith zipfile.ZipFile(output_zip_file, 'w', zipfile.ZIP_STORED) as zipf:\n    for file in tqdm(file_paths, desc=\"Zipping files\", unit=\"file\"):\n        zipf.write(file, os.path.relpath(file, dir_to_zip))\n\nprint(f\"Zipping completed: {output_zip_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T21:54:06.802613Z","iopub.execute_input":"2025-01-13T21:54:06.802936Z","iopub.status.idle":"2025-01-13T21:54:15.018838Z","shell.execute_reply.started":"2025-01-13T21:54:06.802912Z","shell.execute_reply":"2025-01-13T21:54:15.017981Z"}},"outputs":[{"name":"stderr","text":"Zipping files: 100%|██████████| 11/11 [00:08<00:00,  1.34file/s]","output_type":"stream"},{"name":"stdout","text":"Zipping completed: checkpoint-2700_3b_ft.zip\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create a download link for the zip file\nFileLink('/kaggle/working/checkpoint-2700_3b_ft.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T22:02:29.309671Z","iopub.execute_input":"2025-01-13T22:02:29.310004Z","iopub.status.idle":"2025-01-13T22:02:29.315200Z","shell.execute_reply.started":"2025-01-13T22:02:29.309979Z","shell.execute_reply":"2025-01-13T22:02:29.314293Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/checkpoint-2700_3b_ft.zip","text/html":"<a href='/kaggle/working/checkpoint-2700_3b_ft.zip' target='_blank'>/kaggle/working/checkpoint-2700_3b_ft.zip</a><br>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/llama-3-3b-it-personaB/step_checkpoint/checkpoint-2700\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T21:57:11.994346Z","iopub.execute_input":"2025-01-13T21:57:11.994697Z","iopub.status.idle":"2025-01-13T21:57:11.998273Z","shell.execute_reply.started":"2025-01-13T21:57:11.994668Z","shell.execute_reply":"2025-01-13T21:57:11.997376Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, trust_remote_code=True)\ntokenizer.pad_token_id = tokenizer.eos_token_id\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T22:10:30.268907Z","iopub.execute_input":"2025-01-13T22:10:30.269268Z","iopub.status.idle":"2025-01-13T22:10:30.947371Z","shell.execute_reply.started":"2025-01-13T22:10:30.269241Z","shell.execute_reply":"2025-01-13T22:10:30.946690Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"vocab_size = len(tokenizer)\nprint(vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T22:30:49.999870Z","iopub.execute_input":"2025-01-13T22:30:50.000166Z","iopub.status.idle":"2025-01-13T22:30:50.035742Z","shell.execute_reply.started":"2025-01-13T22:30:50.000144Z","shell.execute_reply":"2025-01-13T22:30:50.034764Z"}},"outputs":[{"name":"stdout","text":"128258\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Load the fine-tuned PEFT model from checkpoint\nmodel = PeftModel.from_pretrained(model, checkpoint_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T22:42:19.169448Z","iopub.execute_input":"2025-01-13T22:42:19.169757Z","iopub.status.idle":"2025-01-13T22:42:21.437287Z","shell.execute_reply.started":"2025-01-13T22:42:19.169733Z","shell.execute_reply":"2025-01-13T22:42:21.436315Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight']\n  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Resize token embeddings if necessary\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T22:44:09.280405Z","iopub.execute_input":"2025-01-13T22:44:09.280710Z","iopub.status.idle":"2025-01-13T22:44:09.318271Z","shell.execute_reply.started":"2025-01-13T22:44:09.280686Z","shell.execute_reply":"2025-01-13T22:44:09.317476Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Embedding(128258, 3072)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"# Define the conversation messages\nmessages = [\n    {\n        \"role\": \"system\",\n        \"content\": \"Persona B's characteristics: My name is David, and I'm a 35-year-old math teacher. \"\n                   \"I like to hike and spend time in nature. I'm married with two kids.\"\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"Morning! I think I saw you at the parent meeting, what's your name?\"\n    }\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:03:14.347370Z","iopub.execute_input":"2025-01-13T23:03:14.347659Z","iopub.status.idle":"2025-01-13T23:03:14.351472Z","shell.execute_reply.started":"2025-01-13T23:03:14.347637Z","shell.execute_reply":"2025-01-13T23:03:14.350577Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# Prepare the prompt using the chat template\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:03:17.531327Z","iopub.execute_input":"2025-01-13T23:03:17.531619Z","iopub.status.idle":"2025-01-13T23:03:17.535365Z","shell.execute_reply.started":"2025-01-13T23:03:17.531594Z","shell.execute_reply":"2025-01-13T23:03:17.534534Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"# Tokenize the input\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:03:21.083533Z","iopub.execute_input":"2025-01-13T23:03:21.083935Z","iopub.status.idle":"2025-01-13T23:03:21.088510Z","shell.execute_reply.started":"2025-01-13T23:03:21.083878Z","shell.execute_reply":"2025-01-13T23:03:21.087766Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"# Run inference with the model\nwith torch.no_grad():\n    outputs = model.generate(\n        input_ids=inputs.input_ids,\n        attention_mask=inputs.attention_mask,\n        max_length=250,\n        num_return_sequences=1\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:03:26.717013Z","iopub.execute_input":"2025-01-13T23:03:26.717423Z","iopub.status.idle":"2025-01-13T23:03:43.218193Z","shell.execute_reply.started":"2025-01-13T23:03:26.717384Z","shell.execute_reply":"2025-01-13T23:03:43.217208Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"# Decode the response from the model\ndecoded_text = tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:03:45.649129Z","iopub.execute_input":"2025-01-13T23:03:45.649454Z","iopub.status.idle":"2025-01-13T23:03:45.654170Z","shell.execute_reply.started":"2025-01-13T23:03:45.649424Z","shell.execute_reply":"2025-01-13T23:03:45.653254Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"# Extract the assistant's reply (if available)\nif \"assistant\" in decoded_text:\n    response = decoded_text.split(\"assistant\", 1)[1].strip()\nelse:\n    response = decoded_text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:03:49.064789Z","iopub.execute_input":"2025-01-13T23:03:49.065162Z","iopub.status.idle":"2025-01-13T23:03:49.069088Z","shell.execute_reply.started":"2025-01-13T23:03:49.065134Z","shell.execute_reply":"2025-01-13T23:03:49.068089Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"# Print the assistant's reply\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:03:52.484242Z","iopub.execute_input":"2025-01-13T23:03:52.484526Z","iopub.status.idle":"2025-01-13T23:03:52.488847Z","shell.execute_reply.started":"2025-01-13T23:03:52.484502Z","shell.execute_reply":"2025-01-13T23:03:52.487999Z"}},"outputs":[{"name":"stdout","text":"Morning! My name is David, nice to meet you. Yeah, I was at the parent meeting, just discussing the upcoming math tests with the other teachers. How about you, how's your day going so far?\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:06:37.368345Z","iopub.execute_input":"2025-01-13T23:06:37.368729Z","iopub.status.idle":"2025-01-13T23:06:46.977251Z","shell.execute_reply.started":"2025-01-13T23:06:37.368697Z","shell.execute_reply":"2025-01-13T23:06:46.975966Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"newhf_token = user_secrets.get_secret(\"ft_hfhub\")\nlogin(token = newhf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:13:58.277225Z","iopub.execute_input":"2025-01-13T23:13:58.277552Z","iopub.status.idle":"2025-01-13T23:13:58.551953Z","shell.execute_reply.started":"2025-01-13T23:13:58.277523Z","shell.execute_reply":"2025-01-13T23:13:58.551090Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"trainer.model.push_to_hub(new_model, use_temp_dir=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T23:14:03.357860Z","iopub.execute_input":"2025-01-13T23:14:03.358166Z","iopub.status.idle":"2025-01-13T23:15:47.451718Z","shell.execute_reply.started":"2025-01-13T23:14:03.358142Z","shell.execute_reply":"2025-01-13T23:15:47.451051Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aa451c0b36f4db792d33dbae6e01578"}},"metadata":{}},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ishitas2365/llama-3-3b-it-personaB/commit/10d5f9a99e95d012eec37e0e272a0cbfd6cd4b17', commit_message='Upload model', commit_description='', oid='10d5f9a99e95d012eec37e0e272a0cbfd6cd4b17', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ishitas2365/llama-3-3b-it-personaB', endpoint='https://huggingface.co', repo_type='model', repo_id='ishitas2365/llama-3-3b-it-personaB'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":87}]}