{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10490646,"sourceType":"datasetVersion","datasetId":6495433}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install PyTorch and Torchvision (if not pre-installed)\n!pip install torch torchvision\n\n# Install additional libraries\n!pip install matplotlib Pillow scikit-learn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T15:29:17.602079Z","iopub.execute_input":"2025-01-17T15:29:17.602399Z","iopub.status.idle":"2025-01-17T15:29:24.922070Z","shell.execute_reply.started":"2025-01-17T15:29:17.602371Z","shell.execute_reply":"2025-01-17T15:29:24.921274Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T15:29:24.923502Z","iopub.execute_input":"2025-01-17T15:29:24.923844Z","iopub.status.idle":"2025-01-17T15:29:30.799383Z","shell.execute_reply.started":"2025-01-17T15:29:24.923808Z","shell.execute_reply":"2025-01-17T15:29:30.798504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset Definition\nclass TreeDataset(Dataset):\n    def __init__(self, normal_dir, decorated_dir, indices=None, transform=None):\n        self.normal_paths = sorted([os.path.join(normal_dir, img) for img in os.listdir(normal_dir)])\n        self.decorated_paths = sorted([os.path.join(decorated_dir, img) for img in os.listdir(decorated_dir)])\n        if indices is not None:\n            self.normal_paths = [self.normal_paths[i] for i in indices]\n            self.decorated_paths = [self.decorated_paths[i] for i in indices]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.normal_paths)\n\n    def __getitem__(self, idx):\n        normal_image = Image.open(self.normal_paths[idx]).convert('RGB')\n        decorated_image = Image.open(self.decorated_paths[idx]).convert('RGB')\n        if self.transform:\n            normal_image = self.transform(normal_image)\n            decorated_image = self.transform(decorated_image)\n        return normal_image, decorated_image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T15:29:30.801330Z","iopub.execute_input":"2025-01-17T15:29:30.801712Z","iopub.status.idle":"2025-01-17T15:29:30.807515Z","shell.execute_reply.started":"2025-01-17T15:29:30.801688Z","shell.execute_reply":"2025-01-17T15:29:30.806749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Residual Block Definition\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super(ResidualBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm2d(channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm2d(channels),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generator with Residual Blocks\nclass GeneratorResNet(nn.Module):\n    def __init__(self, input_channels=3, output_channels=3, num_residuals=9):\n        super(GeneratorResNet, self).__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(input_channels, 64, kernel_size=7, stride=1, padding=3),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n        self.downsampling = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True),\n        )\n        self.residuals = nn.Sequential(*[ResidualBlock(256) for _ in range(num_residuals)])\n        self.upsampling = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n        self.output = nn.Sequential(\n            nn.Conv2d(64, output_channels, kernel_size=7, stride=1, padding=3),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.initial(x)\n        x = self.downsampling(x)\n        x = self.residuals(x)\n        x = self.upsampling(x)\n        return self.output(x)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T15:29:30.808590Z","iopub.execute_input":"2025-01-17T15:29:30.808936Z","iopub.status.idle":"2025-01-17T15:29:30.823271Z","shell.execute_reply.started":"2025-01-17T15:29:30.808903Z","shell.execute_reply":"2025-01-17T15:29:30.822466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Discriminator Definition (PatchGAN)\nclass Discriminator(nn.Module):\n    def __init__(self, input_channels=3):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),\n            nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1),\n        )\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_cyclegan(generator_g, generator_f, discriminator_x, discriminator_y, train_loader, val_loader, device, num_epochs=100):\n    opt_g = torch.optim.Adam(list(generator_g.parameters()) + list(generator_f.parameters()), lr=1e-4, betas=(0.5, 0.999))\n    opt_d_x = torch.optim.Adam(discriminator_x.parameters(), lr=1e-4, betas=(0.5, 0.999))\n    opt_d_y = torch.optim.Adam(discriminator_y.parameters(), lr=1e-4, betas=(0.5, 0.999))\n\n    mse_loss = nn.MSELoss()\n    l1_loss = nn.L1Loss()\n\n    for epoch in range(num_epochs):\n        generator_g.train()\n        generator_f.train()\n\n        total_loss_g, total_loss_d_x, total_loss_d_y = 0, 0, 0\n\n        for normal, decorated in train_loader:\n            normal = normal.to(device)\n            decorated = decorated.to(device)\n\n            # Train Generators\n            opt_g.zero_grad()\n            fake_decorated = generator_g(normal)\n            fake_normal = generator_f(decorated)\n\n            loss_g_adv = mse_loss(discriminator_y(fake_decorated), torch.ones_like(discriminator_y(fake_decorated)))\n            cycle_normal = generator_f(fake_decorated)\n            cycle_decorated = generator_g(fake_normal)\n            loss_cycle = l1_loss(cycle_normal, normal) + l1_loss(cycle_decorated, decorated)\n\n            loss_g = loss_g_adv + 10 * loss_cycle\n            loss_g.backward()\n            opt_g.step()\n\n            # Train Discriminators\n            opt_d_x.zero_grad()\n            opt_d_y.zero_grad()\n\n            loss_d_x_real = mse_loss(discriminator_x(decorated), torch.ones_like(discriminator_x(decorated)))\n            loss_d_x_fake = mse_loss(discriminator_x(fake_decorated.detach()), torch.zeros_like(discriminator_x(fake_decorated.detach())))\n            loss_d_x = (loss_d_x_real + loss_d_x_fake) * 0.5\n\n            loss_d_y_real = mse_loss(discriminator_y(normal), torch.ones_like(discriminator_y(normal)))\n            loss_d_y_fake = mse_loss(discriminator_y(fake_normal.detach()), torch.zeros_like(discriminator_y(fake_normal.detach())))\n            loss_d_y = (loss_d_y_real + loss_d_y_fake) * 0.5\n\n            loss_d_x.backward()\n            loss_d_y.backward()\n            opt_d_x.step()\n            opt_d_y.step()\n\n            total_loss_g += loss_g.item()\n            total_loss_d_x += loss_d_x.item()\n            total_loss_d_y += loss_d_y.item()\n\n        # Show Images\n        if (epoch + 1) % 10 == 0:\n            generator_g.eval()\n            generator_f.eval()\n            with torch.no_grad():\n                for i, (normal, decorated) in enumerate(val_loader):\n                    if i >= 3:\n                        break\n\n                    normal = normal.to(device)\n                    decorated = decorated.to(device)\n\n                    fake_decorated = generator_g(normal)\n                    fake_normal = generator_f(decorated)\n\n                    normal_np = normal[0].permute(1, 2, 0).cpu().numpy()\n                    decorated_np = decorated[0].permute(1, 2, 0).cpu().numpy()\n                    fake_decorated_np = fake_decorated[0].permute(1, 2, 0).cpu().numpy()\n                    fake_normal_np = fake_normal[0].permute(1, 2, 0).cpu().numpy()\n\n                    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n                    axs[0].imshow((normal_np + 1) / 2)\n                    axs[0].set_title(\"Normal Tree\")\n                    axs[1].imshow((decorated_np + 1) / 2)\n                    axs[1].set_title(\"Decorated Tree\")\n                    axs[2].imshow((fake_decorated_np + 1) / 2)\n                    axs[2].set_title(\"Fake Decorated Tree\")\n                    axs[3].imshow((fake_normal_np + 1) / 2)\n                    axs[3].set_title(\"Fake Normal Tree\")\n                    plt.show()\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss G: {total_loss_g:.4f}, Loss D_x: {total_loss_d_x:.4f}, Loss D_y: {total_loss_d_y:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T15:29:30.824093Z","iopub.execute_input":"2025-01-17T15:29:30.824380Z","iopub.status.idle":"2025-01-17T15:29:30.837553Z","shell.execute_reply.started":"2025-01-17T15:29:30.824348Z","shell.execute_reply":"2025-01-17T15:29:30.836646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameters\nbatch_size = 4\nimage_size = 128\nnum_epochs = 300\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transformations for the dataset\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths to the dataset directories\nnormal_tree_dir = \"/kaggle/input/christmas-trees/undecorated\"\ndecorated_tree_dir = \"/kaggle/input/christmas-trees/decorated\"  \n\n# Dataset Preparation\nnormal_images = sorted(os.listdir(normal_tree_dir))\ndecorated_images = sorted(os.listdir(decorated_tree_dir))\n\n# Ensure datasets have the same length (to avoid imbalance issues)\nmin_dataset_size = min(len(normal_images), len(decorated_images))\n\nnormal_indices = list(range(len(normal_images)))[:min_dataset_size]\ndecorated_indices = list(range(len(decorated_images)))[:min_dataset_size]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-validation split\ntrain_indices, val_indices = train_test_split(\n    normal_indices, test_size=0.2, random_state=42\n)\n\n# Create dataset objects\ntrain_dataset = TreeDataset(\n    normal_dir=normal_tree_dir,\n    decorated_dir=decorated_tree_dir,\n    indices=train_indices,\n    transform=transform,\n)\n\nval_dataset = TreeDataset(\n    normal_dir=normal_tree_dir,\n    decorated_dir=decorated_tree_dir,\n    indices=val_indices,\n    transform=transform,\n)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize CycleGAN Models\ngenerator_g = GeneratorResNet().to(device)  # Normal → Decorated\ngenerator_f = GeneratorResNet().to(device)  # Decorated → Normal\ndiscriminator_x = Discriminator().to(device)  # For Decorated Trees\ndiscriminator_y = Discriminator().to(device)  # For Normal Trees\n\n# Training the CycleGAN\ntrain_cyclegan(\n    generator_g=generator_g,\n    generator_f=generator_f,\n    discriminator_x=discriminator_x,\n    discriminator_y=discriminator_y,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    device=device,\n    num_epochs=num_epochs,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T15:29:30.838304Z","iopub.execute_input":"2025-01-17T15:29:30.838552Z","iopub.status.idle":"2025-01-17T17:30:27.550694Z","shell.execute_reply.started":"2025-01-17T15:29:30.838533Z","shell.execute_reply":"2025-01-17T17:30:27.549532Z"}},"outputs":[],"execution_count":null}]}