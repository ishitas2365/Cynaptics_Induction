{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install numpy tqdm matplotlib torch torchvision","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Subset\nimport numpy as np\nfrom PIL import Image\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as tv_data\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameters\nimages_per_class = 4000  # Number of images per class\nresize_to = (64, 64)  # Target size\noutput_dir = \"./cifar10_resized_shuffled\"  # Output folder\n\ntransform = transforms.Compose([\n    transforms.Resize((64, 64)),  # Resize the image if needed\n    transforms.ToTensor()    # Convert the image to a tensor\n    #transforms.Normalize((0.5,), (0.5,))  # Normalize the image\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cifar10 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Group images by class\nclass_indices = {i: [] for i in range(10)}  # A dictionary to hold indices of each class\nfor idx, (_, label) in enumerate(cifar10):\n    class_indices[label].append(idx)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"selected_indices = []\nfor class_id, indices in class_indices.items():\n    selected_indices.extend(np.random.choice(indices, images_per_class, replace=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.shuffle(selected_indices)\n\n# Subset the dataset\nsubset_dataset = Subset(cifar10, selected_indices)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a DataLoader\nbatch_size = 128\ndataloader = DataLoader(\n    subset_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(output_dir, exist_ok=True)\nos.makedirs('./images', exist_ok=True)\nos.makedirs('./weights', exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.transforms import ToPILImage\n\n# Save all images without class labels\nfor idx in range(len(subset_dataset)):\n    img, _ = subset_dataset[idx]  # Get the image (Tensor) and label (we discard the label)\n    img_pil = transforms.ToPILImage()(img)  # Convert tensor to PIL image\n    img_pil.save(os.path.join(output_dir, f\"image_{idx}.png\"))  # Save image\n\nprint(f\"Shuffled, resized images saved in {output_dir} (20,000 images total).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_files = sorted(os.listdir(output_dir))\nimport matplotlib.pyplot as plt\n# Display the first 10 images\nplt.figure(figsize=(10, 10))\nfor i, img_file in enumerate(image_files[:10]):  # Adjust the range to display more/less images\n    img = Image.open(os.path.join(output_dir, img_file))\n    plt.subplot(5, 5, i + 1)  # Change grid size as needed\n    plt.imshow(img)\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"current_device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(current_device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ngpu = 1   # number of GPUs \nnz = 100   #dimensionality of the noise vector\n\n# initialises the weights of the neural network for stable training\ndef weights_normal_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:    \n        # initialises weights with normal distribution with mean=0, standard deviation=0.02 to prevent exploding/vanishing gradients\n        m.weight.data.normal_(0.0, 0.02)    \n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n        # sets the bias of this layer=0 so that they adjust later on without any prior intervention\n        m.bias.data.fill_(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Disc_model(nn.Module):\n    def __init__(self, ngpu):\n        super(Disc_model, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.Conv2d(num_channels, 64, 4, 2, 1, bias=False),  #kernel=4*4, stride=2, padding=1\n            nn.LeakyReLU(0.2, inplace=True),   #alpha=0.2\n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        output = self.main(input)\n        return output.view(-1, 1).squeeze(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Gen_model(nn.Module):\n    def __init__(self, ngpu):\n        super(Gen_model, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(nz, 512, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, num_channels, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n        \n    def forward(self, input):\n        output = self.main(input)\n        return output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fixed_noise = torch.randn(128, nz, 1, 1).to(current_device)\nreal_label = 1\nfake_label = 0\n\nniter = 25\ng_loss = []\nd_loss = []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_channels=3\nmodel_Gen = Gen_model(ngpu).to(current_device)\nmodel_Gen.apply(weights_normal_init)\nmodel_Disc = Disc_model(ngpu).to(current_device)\nmodel_Disc.apply(weights_normal_init)\nloss_func = nn.BCELoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizerD = optim.Adam(model_Disc.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerG = optim.Adam(model_Gen.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in tqdm(range(niter), total = niter):\n    for i, data in enumerate(dataloader, 0):\n        model_Disc.zero_grad()\n        device_model = data[0].to(current_device)\n        batch_size = device_model.size(0)\n        label = torch.full((batch_size,), real_label).to(current_device)\n\n        output = model_Disc(device_model) # Discriminator output\n        disc_error_real = loss_func(output.float(), label.float())\n        disc_error_real.backward() # disc loss for real image\n        D_x = output.mean().item()\n\n        noise = torch.randn(batch_size, nz, 1, 1).to(current_device) # create noise\n        fake = model_Gen(noise) # Fake image\n        label.fill_(fake_label) # Fill with 0\n        output = model_Disc(fake.detach())\n        disc_error_fake = loss_func(output.float(), label.float()) # disc loss for fake image\n        disc_error_fake.backward()\n        D_G_z1 = output.mean().item()\n        disc_error = disc_error_real + disc_error_fake\n        optimizerD.step()\n        model_Gen.zero_grad()\n        label.fill_(real_label) # fill with 1\n        output = model_Disc(fake.float()) # disc output\n        gen_error = loss_func(output.float(), label.float())\n        gen_error.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        print(f'[{epoch}/{niter}][{i}/{len(dataloader)}] Loss_D: {disc_error.item():.4f} Loss_G: {gen_error.item():.4f} D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n\n        if i % 100 == 0: # save images every 100 steps\n            print('saving the output')\n            vutils.save_image(device_model,'./images/real_samples.png',normalize=True)\n            fake = model_Gen(fixed_noise)\n            vutils.save_image(fake.detach(),'./images/fake_samples_epoch_%03d.png' % (epoch),normalize=True)\n    # Save images every 2 epochs\n    if epoch % 2 == 0:\n        with torch.no_grad():\n            fixed_fake = model_Gen(fixed_noise).detach().cpu()\n        grid = vutils.make_grid(fixed_fake[:25], nrow=5)  # Arrange 25 images in a grid (5x5)\n        \n        # Display the grid using matplotlib\n        plt.figure(figsize=(10, 10))\n        plt.axis(\"off\")\n        plt.title(f\"Epoch {epoch}: Generated Images\")\n        plt.imshow(grid.permute(1, 2, 0))  # Change dimensions from (C, H, W) to (H, W, C)\n        plt.show()\n        \n    torch.save(model_Gen.state_dict(), 'weights/model_Gen_epoch_%d.pth' % (epoch))\n    torch.save(model_Disc.state_dict(), 'weights/model_Disc_epoch_%d.pth' % (epoch))\n            ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}